<html>

<header>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="Author" content="Tianyu Zhao">
<link rel="stylesheet" type="text/css" href="stylesheets/style.css">
<title>ZHAO Tianyu - homepage</title>
</header>
 
<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109982067-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109982067-1');
</script>

<body>

<div class="image-container">
	<img src="assets/my_cat.jpg" alt="My cat" width="100%">
	<span class="image-text">This is my cat.</span>
</div>

<h3>ZHAO Tianyu 趙天雨</h3>

<a href="https://github.com/zhaoting">Github Page</a> | <a href="https://scholar.google.com/citations?user=e0_swMAAAAAJ">Google Scholar</a> | <a href="https://www.semanticscholar.org/author/Tianyu-Zhao/46887780">Semantic Scholar</a>
<br><br>

Address: Shibuya 2-24-12 39F WeWork, Shibuya-ku, Tokyo 150-6139, JAPAN<br>
E-mail: zhaoty.ting[at]gmail.com<br>

<br>
<span class="update_date">Updated on 2024/01/10</span>

<br>
<hr>

<p>
	I am a researcher at <a href="https://corp.rinna.co.jp/">rinna Co., Ltd</a>.
</p>
<p>
	My research topics include <span class="topic">Alignment</span>, <span class="topic">Dialogue System</span>, <span class="topic">Large Language Model</span>.
	<br>
	<span class="topic"> General NLP+ML </span> is a part of my interest as well.
</p>
<p>
	I have led the development of rinna's Japanese language models
	<br>
	<span class="padded"><i>the qwen-based nekomata</i> series (
		<a href="https://huggingface.co/rinna/nekomata-14b">14b pre-trained</a>,
		<a href="https://huggingface.co/rinna/nekomata-14b-instruction">14b instruction</a>,
		<a href="https://huggingface.co/rinna/nekomata-7b">7b pre-trained</a>,
		<a href="https://huggingface.co/rinna/nekomata-7b-instruction">7b instruction</a>
	),</span>
	<br>
	<span class="padded"><i>the llama2-based youri</i> series (
		<a href="https://huggingface.co/rinna/youri-7b">7b pre-trained</a>,
		<a href="https://huggingface.co/rinna/youri-7b-instruction">7b instruction</a>,
		<a href="https://huggingface.co/rinna/youri-7b-chat">7b chat</a>
	),</span>
	<br>
	<span class="padded"><i>the en-ja bilingual 4b gpt-neox</i> series (
		<a href="https://huggingface.co/rinna/bilingual-gpt-neox-4b">pre-trained</a>,
		<a href="https://huggingface.co/rinna/bilingual-gpt-neox-4b-8k">8k context size</a>,
		<a href="https://huggingface.co/rinna/bilingual-gpt-neox-4b-sft">instruction sft</a>,
		<a href="https://huggingface.co/rinna/bilingual-gpt-neox-4b-ppo">instruction ppo</a>
	),</span>
	<br>
	<span class="padded"><i>the ja 3.6b gpt-neox</i> series (
		<a href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b">pre-trained</a>,
		<a href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-sft">sft</a>,
		<a href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-sft-v2">sft-v2</a>,
		<a href="https://huggingface.co/rinna/japanese-gpt-neox-3.6b-instruction-ppo">ppo</a>
	),</span>
	<br>
	<span class="padded">and earlier models (
		<a href="https://huggingface.co/rinna/japanese-gpt-1b">gpt 1b</a>,
		<a href="https://huggingface.co/rinna/japanese-gpt2-medium">gpt2 medium</a>,
		<a href="https://huggingface.co/rinna/japanese-roberta-base">roberta base</a>,
		etc.
	)</span>
</p>

<hr>

<h4>Work Experience</h4>
<div class="padded">
	2020.10 - Present <br>
	Researcher @ rinna Co., Ltd. <br>
	Alignment, Dialogue, and LLM <br>
	<br>
	2019.10 - 2019.12 <br>
	Research SDE Intern @ Microsoft Development, Rinna Team <br>
	Pre-trained models for Japanese dialogues <br>
	<br>
	2015.12 - 2020.9 <br>
	RA @ Kyoto University, ERATO Symbiotic Human-Robot Interaction Project <br>
	Dialogue system <br>
</div>

<h4>Education Experience</h4>
<div class="padded">
	2017.10 - 2020.9, Ph.D., Intelligence Science and Technology, Kyoto University, Japan | Supervisor: Tatsuya Kawahara<br>
	2015.10 - 2017.9, M.Eng., Intelligence Science and Technology, Kyoto University, Japan | Supervisor: Tatsuya Kawahara<br>
	2011.9 - 2015.7, B.Sc., Computer Science and Technology, Peking University, China | Supervisor: Yunfang Wu</a><br>
</div>

<br>
<hr>

<h4>Publications</h4>
<div class="padded">

	<strong> --- 2023 --- </strong> <br>
	An integration of pre-trained speech and language models for end-to-end speech recognition <br>
	<i class="authors"> Yukiya Hono, Koh Mitsuda, <ins>TyZ</ins>, Kentaro Mitsui, Toshiaki Wakatsuki, and Kei Sawada </i> <br>
	<a href=https://arxiv.org/abs/2312.03668>arxiv</a> <a href="https://huggingface.co/rinna/nue-asr">model</a> <a href="https://github.com/rinnakk/nue-asr">code</a> (2023) <br>
	<br>
	Focused prefix tuning for controllable text generation <br>
	<i class="authors"> Congda Ma, <ins>TyZ</ins>, Makoto Shing, Kei Sawada, and Manabu Okumura </i> <br>
	<a href=https://arxiv.org/abs/2306.00369>arxiv</a> Short paper at ACL 2023 <br>
	<br>

	<strong> --- 2022 --- </strong> <br>
	End-to-end text-to-speech based on latent representation of speaking styles using spontaneous dialogue <br>
	<i class="authors"> Kentaro Mitsui, <ins>TyZ</ins>, Kei Sawada, Yukiya Hono, Yoshihiko Nankaku, and Keiichi Tokuda </i> <br>
	<a href=https://arxiv.org/abs/2206.12040>arxiv</a> <a href=https://rinnakk.github.io/research/publications/DialogueTTS>demo</a> Regular paper at Interspeech 2022 <br>
	<br>

	<strong> --- 2021 --- </strong> <br>
	Multi-referenced training for dialogue response generation <br>
	<i class="authors"> <ins>TyZ</ins> and Tatsuya Kawahara </i> <br>
	<a href=https://aclanthology.org/2021.sigdial-1.20.pdf>PDF</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> Long paper at SIGDIAL 2021 <br>
	<br>

	<strong> --- 2020 --- </strong> <br>
	Utterance abstraction and response diversity for open-domain dialogue systems <br>
	<i class="authors"> <ins>TyZ</ins> </i> <br>
	<a href=https://repository.kulib.kyoto-u.ac.jp/dspace/bitstream/2433/259067/2/djohk00729.pdf>PDF</a> Ph.D. thesis <br>
	<br>
	Designing precise and robust dialogue response evaluators <br>
	<i class="authors"> <ins>TyZ</ins>, Divesh Lala, and Tatsuya Kawahara </i> <br>
	<a href=https://www.aclweb.org/anthology/2020.acl-main.4.pdf>PDF</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> Short paper at ACL 2020<br>
	<br>
	Topic-relevant response generation using optimal transport for an open-domain dialog system <br>
	<i class="authors"> Shuying Zhang, <ins>TyZ</ins>, and Tatsuya Kawahara </i> <br>
	<a href=https://aclanthology.org/2020.coling-main.359.pdf>PDF</a> Regular paper at COLING 2020<br>
	<br>

	<strong> --- 2019 --- </strong> <br>
	Improved end-to-end speech emotion recognition using self attention mechanism and multitask learning <br>
	<i class="authors"> Yuanchao Li, <ins>TyZ</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LYC-INTERSP19.pdf>PDF</a> <a href=https://github.com/KrishnaDN/speech-emotion-recognition-using-self-attention>non-official code</a> Regular paper (oral) at Interspeech 2019 <br>
	<br>
	Effective incorporation of speaker information in utterance encoding in dialog <br>
	<i class="authors"> <ins>TyZ</ins> and Tatsuya Kawahara </i> <br>
	<a href=https://arxiv.org/abs/1907.05599>arxiv</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> (2019) <br>
	<br>
	Content word-based sentence decoding and evaluating for open-domain neural response generation <br>
	<i class="authors"> <ins>TyZ</ins>, Shinsuke Mori, and Tatsuya Kawahara </i> <br>
	<a href=https://arxiv.org/abs/1905.13438>arxiv</a> (2019) <br>
	<br>
	Joint dialog act segmentation and recognition in human conversations using attention to dialog context <br>
	<i class="authors"> <ins>TyZ</ins> and Tatsuya Kawahara </i> <br>
	<a href=https://www.sciencedirect.com/science/article/pii/S0885230818304030>Link</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> Journal paper at Elsevier CSL 2019 <br>
	<br>

	<strong> --- 2018 --- </strong> <br>
	A unified neural architecture for joint dialog act segmentation and recognition in spoken dialog system <br>
	<i class="authors"> <ins>TyZ</ins> and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/ZHA-SIGDIAL18.pdf>PDF</a> Long paper at SIGDIAL 2018<br>
	<br>

	<strong> --- 2017 --- </strong> <br>
	Joint learning of dialog act segmentation and recognition in spoken dialog using neural networks <br>
	<i class="authors"> <ins>TyZ</ins> and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/ZHA-IJCNLP17.pdf>PDF</a> Long paper (oral) at IJCNLP 2017 <br>
	<br>
	A conversational dialogue manager for the humanoid robot ERICA <br>
	<i class="authors"> Pierrick Milhorat, Divesh Lala, Koji Inoue, <ins>TyZ</ins>, Masanari Ishida, Katsuya Takanashi, Shizuka
	Nakamura, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/MIL-IWSDS17.pdf>PDF</a> Long paper at IWSDS 2017 <br>
	<br>

	<strong> --- 2016 --- </strong> <br>
	Multimodal interaction with the autonomous android ERICA <br>
	<i class="authors"> Divesh Lala, Pierrick Milhorat, Koji Inoue, <ins>TyZ</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LAL-ICMI16.pdf>PDF</a> Demo paper at ICMI 2016 <br>
	<br>
	Talking with ERICA, an autonomous android <br>
	<i class="authors"> Koji Inoue, Pierrick Milhorat, Divesh Lala, <ins>TyZ</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/INO-SIGDIAL16.pdf>PDF</a> Demo paper at SIGDIAL 2016 <br>
	<br>
	Interactional and pragmatics-related prosodic patterns in Mandarin dialog <br>
	<i class="authors"> Nigel Ward, Yuanchao Li, <ins>TyZ</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/WAR-SPROSODY16.pdf>PDF</a> Regular paper at Speech Prosody 2016 <br>
	<br>

</div>

<h4>Talks</h4>
<div class="padded">
	2023/06/29 <br>
	日本語LLMの最先端 <br>
	<a href=https://wandb.connpass.com/event/286694>Link</a> Weights and Biases Tokyo Meetup #5 @ Tokyo <br>
	<br>
	
	2022/12/09 <br>
	小冰如何利用FasterTransformer 实现大规模语言模型的产品级部署 <br>
	<a href=https://ccf.org.cn/cncc2022/schedule_d_4076>Link</a> CNCC 2022 @ Online <br>
	<br>

	2021/05/20 <br>
	Conversational AI that Learns from the Unverbalized <br>
	<a href=https://www.microsoft.com/ja-jp/events/azureaidays/2021.aspx>Link</a> Microsoft Azure AI Days 2021 @ Online <br>
	<br>
</div>

<h4>Academic Activities</h4>
<div class="padded">
	Reviewer: ACL 2018/2020/2021/2023, ACL ARR, COLING 2020, EMNLP 2020/2021/2023, IJCNLP 2017/2021, NAACL 2021<br>
	<br>
</div>

</body>
</html>
