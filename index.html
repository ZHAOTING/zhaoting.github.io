<html>

<header>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="Author" content="Tianyu Zhao">
<link rel="stylesheet" type="text/css" href="stylesheets/style.css">
<title>Tianyu ZHAO - homepage</title>
</header>

<!-- Global Site Tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-109982067-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-109982067-1');
</script>

<body>

<h3>Tianyu ZHAO 趙天雨</h3>
<h4><a href="http://www.kyoto-u.ac.jp/en">Kyoto University</a> <br>
<a href="http://www.i.kyoto-u.ac.jp/en/">Department of Informatics</a> <br>
<a href="http://sap.ist.i.kyoto-u.ac.jp/EN/"> Speech and Audio Processing Lab. </a>
</h4>

<a href="https://github.com/zhaoting">Github Page</a> | <a href="https://scholar.google.com/citations?user=e0_swMAAAAAJ&hl=zh-CN">Google Scholar</a> | <a href="https://drive.google.com/open?id=1eAs6xBoSnJfdB2To9kCSIVjlJQ37aTrm">Resume</a>
<br><br>

Address: Kyoto University, Sakyo-ku, Kyoto 606-8501, JAPAN<br>
E-mail: zhaoty.ting[at]gmail.com<br>

<br>
<hr>

<h4>Research Topics</h4>
<div class="padded">
	Natural Language Processing, Dialogue, Machine Learning<br>
</div>

<br>
<hr>

<h4>Work Experience</h4>
<div class="padded">
	2020.10 - Present <br>
	Researcher @ Rinna Co., Ltd. <br>
	Dialogue system research <br>
	<br>
	2019.10 - 2019.12 <br>
	RSDE @ Microsoft Development, Rinna Team <br>
	BERT-based dialogue response generator for Japanese conversations <br>
	<br>
	2015.12 - 2020.9 <br>
	RA @ Kyoto University, ERATO Symbiotic Human-Robot Interaction Project <br>
	Dialogue system research <br>
</div>

<h4>Education Experience</h4>
<div class="padded">
	2017.10 - Present, Ph.D., Intelligence Science and Technology, Kyoto University, Japan<br>
	2015.10 - 2017.9, M.Eng., Intelligence Science and Technology, Kyoto University, Japan<br>
	2011.9 - 2015.7, B.Sc., Computer Science and Technology, Peking University, China<br>
</div>

<br>
<hr>

<h4>Publications</h4>
<div class="padded">

	<strong> --- 2020 --- </strong> <br>
	Multi-referenced training for dialogue response generation <br>
	<i> <ins>Tianyu Zhao</ins> and Tatsuya Kawahara </i> <br>
	<a href=https://arxiv.org/pdf/2009.07117>PDF</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> https://arxiv.org/abs/2009.07117 (2020) <br>
	<br>
	Designing precise and robust dialogue response evaluators <br>
	<i> <ins>Tianyu Zhao</ins>, Divesh Lala, and Tatsuya Kawahara </i> <br>
	<a href=https://www.aclweb.org/anthology/2020.acl-main.4.pdf>PDF</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> Short paper at ACL 2020<br>
	<br>
	
	<strong> --- 2019 --- </strong> <br>
	Improved end-to-end speech emotion recognition using self attention mechanism and multitask learning <br>
	<i> Yuanchao Li, <ins>Tianyu Zhao</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LYC-INTERSP19.pdf>PDF</a> <a href=https://github.com/KrishnaDN/speech-emotion-recognition-using-self-attention>non-official code</a> Regular paper (oral) at Interspeech 2019 <br>
	<br>
	Effective incorporation of speaker information in utterance encoding in dialog <br>
	<i> <ins>Tianyu Zhao</ins> and Tatsuya Kawahara </i> <br>
	<a href=https://arxiv.org/pdf/1907.05599>PDF</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> https://arxiv.org/abs/1907.05599 (2019) <br>
	<br>
	Content word-based sentence decoding and evaluating for open-domain neural response generation <br>
	<i> <ins>Tianyu Zhao</ins>, Shinsuke Mori, and Tatsuya Kawahara </i> <br>
	<a href=https://arxiv.org/pdf/1905.13438>PDF</a> https://arxiv.org/abs/1905.13438 (2019) <br>
	<br>
	Joint dialog act segmentation and recognition in human conversations using attention to dialog context <br>
	<i> <ins>Tianyu Zhao</ins> and Tatsuya Kawahara </i> <br>
	<a href=https://www.sciencedirect.com/science/article/pii/S0885230818304030>Link</a> <a href=https://github.com/ZHAOTING/dialog-processing>code</a> Journal paper at Elsevier CSL 2019 <br>
	<br>

	<strong> --- 2018 --- </strong> <br>
	A unified neural architecture for joint dialog act segmentation and recognition in spoken dialog system <br>
	<i> <ins>Tianyu Zhao</ins> and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/ZHA-SIGDIAL18.pdf>PDF</a> Long paper at SIGDIAL 2018<br>
	<br>

	<strong> --- 2017 --- </strong> <br>
	Joint learning of dialog act segmentation and recognition in spoken dialog using neural networks <br>
	<i> <ins>Tianyu Zhao</ins> and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/ZHA-IJCNLP17.pdf>PDF</a> Long paper (oral) at IJCNLP 2017 <br>
	<br>
	A conversational dialogue manager for the humanoid robot ERICA <br>
	<i> Pierrick Milhorat, Divesh Lala, Koji Inoue, <ins>Tianyu Zhao</ins>, Masanari Ishida, Katsuya Takanashi, Shizuka
	Nakamura, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/MIL-IWSDS17.pdf>PDF</a> Long paper at IWSDS 2017 <br>
	<br>

	<strong> --- 2016 --- </strong> <br>
	Multimodal interaction with the autonomous android ERICA <br>
	<i> Divesh Lala, Pierrick Milhorat, Koji Inoue, <ins>Tianyu Zhao</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/LAL-ICMI16.pdf>PDF</a> Demo paper at ICMI 2016 <br>
	<br>
	Talking with ERICA, an autonomous android <br>
	<i> Koji Inoue, Pierrick Milhorat, Divesh Lala, <ins>Tianyu Zhao</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/INO-SIGDIAL16.pdf>PDF</a> Demo paper at SIGDIAL 2016 <br>
	<br>
	Interactional and pragmatics-related prosodic patterns in Mandarin dialog <br>
	<i> Nigel Ward, Yuanchao Li, <ins>Tianyu Zhao</ins>, and Tatsuya Kawahara </i> <br>
	<a href=http://sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/WAR-SPROSODY16.pdf>PDF</a> Regular paper at Speech Prosody 2016 <br>
	<br>

</div>

<h4>Academic Activities</h4>
<div class="padded">
	Reviewer: IJCNLP 2017, ACL 2018/2020, EMNLP 2020, COLING 2020<br>
	<br>
</div>

</body>
</html>
